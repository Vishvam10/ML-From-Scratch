{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "185400fa",
   "metadata": {},
   "source": [
    "# Pre-Processing Text Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2c2e34",
   "metadata": {},
   "source": [
    "HashingVectorizer is the way to go if we're falling short of memory and resources, or we need to perform incremental learning; CountVectorizer is best choice if we need access to the actual tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37ada991",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4afbaf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ['One way to get a sense of the daring of this personal statement, written by a student who aims to study film at Columbia University, is simply to consider the allusions he makes throughout his statement. With neither apology nor obvious humility, this writer makes references to Steven Spielberg, Woody Allen, Jean-Luc Godard, Jean Vigo, Terrence Malick, and David Gordon Green. Further, this writer takes the unusual step of using section headings in his personal statement, including, on his first page “Poetry,” “Plastics,” and “Children.” But no matter how creative this writer is, of course, we must ultimately judge him on his evidenced ability as a filmmaker. In that regard, he showcases his ease with talking about films and directors, posits an analogy about student filmmaking (“directing your own material is like parenting”), and discusses the success of his nineteen-minute senior project, “Burying Dvorak”—a film he promoted by taking a year off after graduation, successfully landing it in more than 20 film festivals. As he closes his essay, he makes a specific pitch for Columbia University, where he hopes to continue “to discover my own voice, my own poetry.”', 'For the lengthy sample essay from the student in biological science, the extensive length and scientific depth are necessary because the student is applying for the highly competitive STAR Fellowship. The STAR (Science to Achieve Results) program offers graduate fellowships through the US Environmental Protection Agency (EPA), funding several years of study. Given the competitiveness of the process and the EPA’s mission of environmental protection, it is vital that this student presents a viable, environmentally important project in a persuasive, professional manner. To achieve this, the writer successfully approaches the essay as she would a thesis proposal, using science-related section heads, providing original figures and data, focusing heavily on future research goals, and essentially performing a literature review, citing 19 sources ranging from basic textbooks to refereed journals. The result is a powerful essay with scientific depth.',         'In the first sample essay from mechanical engineering, what stands out immediately are the length and the photographs. In this case, the student was applying for an engineering scholarship, so he was given room to flesh out technical material as well as address issues such as personal motivations one would expect to read in a personal statement. Much of the essay is given to a discussion of his thesis work, which involves the examination of “the propagation of a flame in a small glass tube.” The figures depict the experimental work and represent the success of preliminary thesis results, visually indicating the likely point at which the flame reached detonation.']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0bb044",
   "metadata": {},
   "source": [
    "### Using Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a60a0aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 247)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_vectorizer = CountVectorizer()\n",
    "X_c = c_vectorizer.fit_transform(text)\n",
    "X_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8f6fca6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 139)\t1\n",
      "  (0, 231)\t1\n",
      "  (0, 218)\t6\n",
      "  (0, 78)\t1\n",
      "  (0, 185)\t1\n",
      "  (0, 135)\t5\n",
      "  (0, 213)\t4\n",
      "  (0, 37)\t1\n",
      "  (0, 215)\t4\n",
      "  (0, 146)\t2\n",
      "  (0, 197)\t3\n",
      "  (0, 243)\t1\n",
      "  (0, 25)\t2\n",
      "  (0, 200)\t2\n",
      "  (0, 237)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 201)\t1\n",
      "  (0, 65)\t3\n",
      "  (0, 19)\t1\n",
      "  (0, 30)\t2\n",
      "  (0, 221)\t2\n",
      "  (0, 103)\t3\n",
      "  (0, 189)\t1\n",
      "  (0, 33)\t1\n",
      "  (0, 10)\t1\n",
      "  :\t:\n",
      "  (2, 204)\t1\n",
      "  (2, 125)\t1\n",
      "  (2, 58)\t1\n",
      "  (2, 168)\t1\n",
      "  (2, 126)\t1\n",
      "  (2, 47)\t1\n",
      "  (2, 240)\t2\n",
      "  (2, 236)\t2\n",
      "  (2, 102)\t1\n",
      "  (2, 57)\t1\n",
      "  (2, 162)\t1\n",
      "  (2, 70)\t2\n",
      "  (2, 190)\t1\n",
      "  (2, 80)\t1\n",
      "  (2, 219)\t1\n",
      "  (2, 40)\t1\n",
      "  (2, 59)\t1\n",
      "  (2, 173)\t1\n",
      "  (2, 155)\t1\n",
      "  (2, 227)\t1\n",
      "  (2, 101)\t1\n",
      "  (2, 113)\t1\n",
      "  (2, 152)\t1\n",
      "  (2, 167)\t1\n",
      "  (2, 42)\t1\n"
     ]
    }
   ],
   "source": [
    "c_vectorizer.vocabulary_ # Each of these represent the features in the dataset\n",
    "print(X_c) # Returns a sparse matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b567ec",
   "metadata": {},
   "source": [
    "### Using Hash Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de9e8819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 50)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_vectorizer = HashingVectorizer(n_features=50)\n",
    "\n",
    "# n_features need to be keep optimum, so that the words are well represented, but without too much legroom\n",
    "X_h = h_vectorizer.fit_transform(text)\n",
    "X_h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41d84214",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t-0.04789131426105757\n",
      "  (0, 2)\t-0.09578262852211514\n",
      "  (0, 3)\t0.09578262852211514\n",
      "  (0, 4)\t0.23945657130528783\n",
      "  (0, 5)\t-0.04789131426105757\n",
      "  (0, 6)\t0.04789131426105757\n",
      "  (0, 7)\t0.04789131426105757\n",
      "  (0, 8)\t-0.04789131426105757\n",
      "  (0, 9)\t0.04789131426105757\n",
      "  (0, 10)\t0.04789131426105757\n",
      "  (0, 11)\t-0.23945657130528783\n",
      "  (0, 12)\t0.04789131426105757\n",
      "  (0, 13)\t0.0\n",
      "  (0, 14)\t-0.09578262852211514\n",
      "  (0, 15)\t0.04789131426105757\n",
      "  (0, 16)\t-0.04789131426105757\n",
      "  (0, 17)\t-0.23945657130528783\n",
      "  (0, 18)\t0.0\n",
      "  (0, 19)\t0.04789131426105757\n",
      "  (0, 20)\t-0.09578262852211514\n",
      "  (0, 21)\t0.09578262852211514\n",
      "  (0, 22)\t-0.19156525704423027\n",
      "  (0, 23)\t-0.04789131426105757\n",
      "  (0, 24)\t0.23945657130528783\n",
      "  (0, 25)\t0.0\n",
      "  (0, 26)\t0.04789131426105757\n",
      "  (0, 27)\t0.04789131426105757\n",
      "  (0, 28)\t0.04789131426105757\n",
      "  (0, 29)\t0.0\n",
      "  (0, 30)\t0.0\n",
      "  (0, 31)\t-0.04789131426105757\n",
      "  (0, 32)\t0.1436739427831727\n",
      "  (0, 33)\t0.0\n",
      "  (0, 34)\t0.09578262852211514\n",
      "  (0, 35)\t0.04789131426105757\n",
      "  (0, 36)\t0.0\n",
      "  (0, 37)\t0.04789131426105757\n",
      "  (0, 38)\t0.09578262852211514\n",
      "  (0, 39)\t0.47891314261057566\n",
      "  (0, 40)\t-0.09578262852211514\n",
      "  (0, 41)\t0.38313051408846055\n",
      "  (0, 42)\t-0.04789131426105757\n",
      "  (0, 43)\t0.19156525704423027\n",
      "  (0, 44)\t0.04789131426105757\n",
      "  (0, 45)\t-0.33523919982740297\n",
      "  (0, 46)\t0.23945657130528783\n",
      "  (0, 47)\t-0.09578262852211514\n",
      "  (0, 48)\t0.0\n",
      "  (0, 49)\t0.04789131426105757\n"
     ]
    }
   ],
   "source": [
    "print(X_h[0]) # For the first element in the list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f16ab0",
   "metadata": {},
   "source": [
    "## Classifying text documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96820de",
   "metadata": {},
   "source": [
    "### HashingVectorizer with SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19404826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import StringIO, BytesIO, TextIOWrapper\n",
    "from zipfile import ZipFile\n",
    "import urllib.request\n",
    "\n",
    "resp = urllib.request.urlopen('https://archive.ics.uci.edu/ml/machine-learning-databases/00331/sentiment%20labelled%20sentences.zip')\n",
    "zipfile = ZipFile(BytesIO(resp.read()))\n",
    "\n",
    "data = TextIOWrapper(zipfile.open('sentiment labelled sentences/amazon_cells_labelled.txt'), encoding='utf-8')\n",
    "\n",
    "df = pd.read_csv(data, sep='\\t')\n",
    "df.columns = ['review', 'sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6362b7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have to jiggle the plug to get it to line up...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0                        Good case, Excellent value.          1\n",
       "1                             Great for the jawbone.          1\n",
       "2  Tied to charger for conversations lasting more...          0\n",
       "3                                  The mic is great.          1\n",
       "4  I have to jiggle the plug to get it to line up...          0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17ec9bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 999 entries, 0 to 998\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     999 non-null    object\n",
      " 1   sentiment  999 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 15.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb1d78fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, 'sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caec16c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((799,), (799,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['review']\n",
    "y = df['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cc2a165",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_vectorizer = HashingVectorizer()\n",
    "classifier = SGDClassifier(penalty='l2', loss='hinge')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e266df51",
   "metadata": {},
   "source": [
    "Now, let's do the learning in parts using `partial_fit()`. Split the dataset equally.\n",
    "\n",
    "On Iteration-1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb20a2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "0.775\n"
     ]
    }
   ],
   "source": [
    "X_train_part1_hashed = h_vectorizer.fit_transform(X_train[0:400])\n",
    "y_train_part1 = y_train[0:400]\n",
    "\n",
    "all_classes = np.unique(df['sentiment'])\n",
    "print(all_classes)\n",
    "\n",
    "classifier.partial_fit(X_train_part1_hashed, y_train_part1, classes=all_classes)\n",
    "\n",
    "# Use the trained classifier on test data\n",
    "X_test_hashed = h_vectorizer.transform(X_test) # Because h_vectorizer was already fit with X_train[0:400] above\n",
    "test_score = classifier.score(X_test_hashed, y_test)\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53af77fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.805\n"
     ]
    }
   ],
   "source": [
    "X_train_part2_hashed = h_vectorizer.fit_transform(X_train[400:])\n",
    "y_train_part2 = y_train[400:]\n",
    "\n",
    "classifier.partial_fit(X_train_part2_hashed, y_train_part2)\n",
    "\n",
    "# Use the trained classifier on test data\n",
    "\n",
    "X_test_hashed = h_vectorizer.transform(X_test) # Because h_vectorizer was already fit with X_train[0:400] above\n",
    "test_score = classifier.score(X_test_hashed, y_test)\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16a1589",
   "metadata": {},
   "source": [
    "**Note that in two partial fit iterations, the test score has increased.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe0140b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c613fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14246770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b974df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
