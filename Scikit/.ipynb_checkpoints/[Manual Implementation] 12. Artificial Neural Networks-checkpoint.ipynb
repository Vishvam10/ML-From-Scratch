{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee8cef6b",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7561258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "seed = 42\n",
    "rng = np.random.default_rng(seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d2d0bb",
   "metadata": {},
   "source": [
    "## Network Class\n",
    "\n",
    "We shall start writing the `Network` class. The two methods that are indispensable for any ML class are :\n",
    "- `fit`\n",
    "- `predict`\n",
    "\n",
    "Fitting a neural network model requires us to compute two passes on the data :\n",
    "- `forward`\n",
    "- `backward`\n",
    "\n",
    "We need to start at some place by initializing the network and various hyperparameters and this requires an `init` method :\n",
    "- `init`\n",
    "\n",
    "In most of these methods, we would have to take the help of certain helper functions :\n",
    "- `activations`\n",
    "- `losses`\n",
    "\n",
    "This is the process. But we will work through it in the reverse order so that each step of the process does not have any forward references :\n",
    "`helpers -> init -> forward -> backward -> fit -> predict`\n",
    "\n",
    "The skeleton of the class is given in the code block that follows. For ease of exposition, we are going to discuss the methods on at a time and then plugh them into the class right at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9ad50e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network :\n",
    "    \n",
    "    def __init__(self, layers, activation_choice=\"relu\", output_choice=\"softmax\", loss_choice=\"cce\") :\n",
    "        pass\n",
    "    \n",
    "    def forward(self, X) :\n",
    "        pass\n",
    "    \n",
    "    def backward(self, Y, Y_hat) :\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, Y, lr=0.01, epochs=100, batch_size=100) :\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X) :\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c33258",
   "metadata": {},
   "source": [
    "## Activation Functions\n",
    "\n",
    "### Hidden Layer\n",
    "\n",
    "We will look at 2 functions for the hidden layers. Both of these functions will be **applied element-wise**. The input to these functions can be scalars, vectors or matrices\n",
    "\n",
    "- Sigmoid :\n",
    "$$\n",
    "    g(z) = \\frac {1} {1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "Its derivative :\n",
    "\n",
    "$$\n",
    "    g'(z) = g(z)(1 - g(z))\n",
    "$$\n",
    "\n",
    "- ReLU ( Rectified Linear Unit ) :\n",
    "$$\n",
    "    g(x)=\\begin{cases}\n",
    "    z, & z \\ge 0 \\\\ \n",
    "    0, & z<0\n",
    "    \\end{cases}\n",
    "$$\n",
    "\n",
    "Its derivative :\n",
    "\n",
    "$$\n",
    "    g'(x)=\\begin{cases}\n",
    "    1, & z \\ge 0 \\\\ \n",
    "    0, & z<0\n",
    "    \\end{cases}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68713c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z) :\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def grad_sigmoid(z) :\n",
    "    return sigmoid(z) * (1 - sigmoid(z))\n",
    "\n",
    "def relu(z) :\n",
    "    return np.where(z >= 0, z, 0)\n",
    "\n",
    "def grad_relu(z) :\n",
    "    return np.where(z >= 0, 1, 0)\n",
    "\n",
    "\n",
    "# A dictionary of activation functions will be used while initializing the network\n",
    "hidden_act = {\"sigmoid\": sigmoid, \"relu\": relu}\n",
    "grad_hiddent_act = {\"sigmoid\": grad_sigmoid, \"relu\": grad_relu}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d249461",
   "metadata": {},
   "source": [
    "## Output Layer\n",
    "\n",
    "We will look at 2 activation functions for the output layer :\n",
    "    \n",
    "- Identity ( For regression )\n",
    "$$\n",
    "    g(z) = z\n",
    "$$\n",
    "\n",
    "- Softmax ( For classification ) :\n",
    "The input to the softmax function will always be a matrix of size $n \\times k$. Since we need a probability distribution for each data point, **the softmax will be computed row-wise**\n",
    "\n",
    "$$\n",
    "    g(\\textbf Z) = \n",
    "    \\begin{pmatrix}\n",
    "    ... & ... & ... \\\\\n",
    "    ... & \\frac {e^{Z_{ij}}} {\\sum \\limits_{j=1}^{k} e^{Z_{ij}}} & ... \\\\\n",
    "    ... & ... & ... \\\\\n",
    "    \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "**To avoid overflow, we will subtract the row-wise maximum from each row while computing the softmax**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc50432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity(z) :\n",
    "    return z\n",
    "\n",
    "def softmax(z) :\n",
    "    \"\"\"\n",
    "    Row-wise softmax\n",
    "    \"\"\"\n",
    "    # Check if z is a matrix\n",
    "    assert z.ndim == 2\n",
    "    \n",
    "    # To prevent overflow, subtract row-wise maximum\n",
    "    z -= z.max(acis=1, keepdims=True)\n",
    "    \n",
    "    # Compute row-wise softmax\n",
    "    prob = np.exp(z) / np.exp(z).sum(axis=1, keepdims=True)\n",
    "    \n",
    "    # Check if each row is a probability distribution\n",
    "    assert np.allclose(prob.sum(axis=1), np.ones(z.shape[0]))\n",
    "    \n",
    "    return prob\n",
    "\n",
    "output_act = {\"softmax\": softmax, \"identity\": identity}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91168bad",
   "metadata": {},
   "source": [
    "## Loss\n",
    "\n",
    "We will use 2 types of losses :\n",
    "\n",
    "- Least Square Loss ( For Regression ) :\n",
    "\n",
    "$$\n",
    "    L(\\hat {\\textbf y}, \\textbf y) = \\frac {1} {2} (\\hat {\\textbf y} - \\textbf y)^{T}(\\hat {\\textbf y} - \\textbf y)\n",
    "$$\n",
    "\n",
    "- Categorial Cross-Entropy Loss ( For Classification ) :\n",
    "    \n",
    "$$\n",
    "    L(\\hat {\\textbf Y}, \\textbf Y) = - \\textbf 1_{n}^T(\\textbf Y \\odot log(\\hat {\\textbf Y})\\textbf1-{k}\n",
    "$$\n",
    "\n",
    "In our implementation, we will assume that the arguments to the loss function are always matrices of size $n \\times k$. In the case of regression, $k = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddd943c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lease_square(y, y_hat) :\n",
    "    return 0.5 * np.sum((y_hat - y) * (y_hat - y))\n",
    "\n",
    "def cce(Y, Y_hat) :\n",
    "    return -np.sum(Y * np.log(Y_hat))\n",
    "\n",
    "losses = {\"least_squares\": least_squares, \"cce\": cce}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f324eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faef91ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdb030d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03255e83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53840cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ce3988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc13befa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7601da0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebecfe98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd455180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676f980e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db84931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ff2fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f746db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f488c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653551e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f01d6f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16af6f92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1cea14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ea5f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f95e6ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8abd2ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
