{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "218c3fc3",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86ef6ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "seed = 42\n",
    "rng = np.random.default_rng(seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc36bff",
   "metadata": {},
   "source": [
    "## Network Class\n",
    "\n",
    "We shall start writing the `Network` class. The two methods that are indispensable for any ML class are :\n",
    "- `fit`\n",
    "- `predict`\n",
    "\n",
    "Fitting a neural network model requires us to compute two passes on the data :\n",
    "- `forward`\n",
    "- `backward`\n",
    "\n",
    "We need to start at some place by initializing the network and various hyperparameters and this requires an `init` method :\n",
    "- `init`\n",
    "\n",
    "In most of these methods, we would have to take the help of certain helper functions :\n",
    "- `activations`\n",
    "- `losses`\n",
    "\n",
    "This is the process. But we will work through it in the reverse order so that each step of the process does not have any forward references :\n",
    "`helpers -> init -> forward -> backward -> fit -> predict`\n",
    "\n",
    "The skeleton of the class is given in the code block that follows. For ease of exposition, we are going to discuss the methods on at a time and then plugh them into the class right at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3025ba83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network :\n",
    "    \n",
    "    def __init__(self, layers, activation_choice=\"relu\", output_choice=\"softmax\", loss_choice=\"cce\") :\n",
    "        pass\n",
    "    \n",
    "    def forward(self, X) :\n",
    "        pass\n",
    "    \n",
    "    def backward(self, Y, Y_hat) :\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, Y, lr=0.01, epochs=100, batch_size=100) :\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X) :\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ff00cd",
   "metadata": {},
   "source": [
    "## Activation Functions\n",
    "\n",
    "### Hidden Layer\n",
    "\n",
    "We will look at 2 functions for the hidden layers. Both of these functions will be **applied element-wise**. The input to these functions can be scalars, vectors or matrices\n",
    "\n",
    "- Sigmoid :\n",
    "$$\n",
    "    g(z) = \\frac {1} {1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "Its derivative :\n",
    "\n",
    "$$\n",
    "    g'(z) = g(z)(1 - g(z))\n",
    "$$\n",
    "\n",
    "- ReLU ( Rectified Linear Unit ) :\n",
    "$$\n",
    "    g(x)=\\begin{cases}\n",
    "    z, & z \\ge 0 \\\\ \n",
    "    0, & z<0\n",
    "    \\end{cases}\n",
    "$$\n",
    "\n",
    "Its derivative :\n",
    "\n",
    "$$\n",
    "    g'(x)=\\begin{cases}\n",
    "    1, & z \\ge 0 \\\\ \n",
    "    0, & z<0\n",
    "    \\end{cases}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3be6548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z) :\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def grad_sigmoid(z) :\n",
    "    return sigmoid(z) * (1 - sigmoid(z))\n",
    "\n",
    "def relu(z) :\n",
    "    return np.where(z >= 0, z, 0)\n",
    "\n",
    "def grad_relu(z) :\n",
    "    return np.where(z >= 0, 1, 0)\n",
    "\n",
    "\n",
    "# A dictionary of activation functions will be used while initializing the network\n",
    "hidden_act = {\"sigmoid\": sigmoid, \"relu\": relu}\n",
    "grad_hidden_act = {\"sigmoid\": grad_sigmoid, \"relu\": grad_relu}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e478cb77",
   "metadata": {},
   "source": [
    "## Output Layer\n",
    "\n",
    "We will look at 2 activation functions for the output layer :\n",
    "    \n",
    "- Identity ( For regression )\n",
    "$$\n",
    "    g(z) = z\n",
    "$$\n",
    "\n",
    "- Softmax ( For classification ) :\n",
    "The input to the softmax function will always be a matrix of size $n \\times k$. Since we need a probability distribution for each data point, **the softmax will be computed row-wise**\n",
    "\n",
    "$$\n",
    "    g(\\textbf Z) = \n",
    "    \\begin{pmatrix}\n",
    "    ... & ... & ... \\\\\n",
    "    ... & \\frac {e^{Z_{ij}}} {\\sum \\limits_{j=1}^{k} e^{Z_{ij}}} & ... \\\\\n",
    "    ... & ... & ... \\\\\n",
    "    \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "**To avoid overflow, we will subtract the row-wise maximum from each row while computing the softmax**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "616a041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity(z) :\n",
    "    return z\n",
    "\n",
    "def softmax(z) :\n",
    "    \"\"\"\n",
    "    Row-wise softmax\n",
    "    \"\"\"\n",
    "    # Check if z is a matrix\n",
    "    assert z.ndim == 2\n",
    "    \n",
    "    # To prevent overflow, subtract row-wise maximum\n",
    "    z -= z.max(axis=1, keepdims=True)\n",
    "    \n",
    "    # Compute row-wise softmax\n",
    "    prob = np.exp(z) / np.exp(z).sum(axis=1, keepdims=True)\n",
    "    \n",
    "    # Check if each row is a probability distribution\n",
    "    assert np.allclose(prob.sum(axis=1), np.ones(z.shape[0]))\n",
    "    \n",
    "    return prob\n",
    "\n",
    "output_act = {\"softmax\": softmax, \"identity\": identity}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2ed8e0",
   "metadata": {},
   "source": [
    "## Loss\n",
    "\n",
    "We will use 2 types of losses :\n",
    "\n",
    "- Least Square Loss ( For Regression ) :\n",
    "\n",
    "$$\n",
    "    L(\\hat {\\textbf y}, \\textbf y) = \\frac {1} {2} (\\hat {\\textbf y} - \\textbf y)^{T}(\\hat {\\textbf y} - \\textbf y)\n",
    "$$\n",
    "\n",
    "- Categorial Cross-Entropy Loss ( For Classification ) :\n",
    "    \n",
    "$$\n",
    "    L(\\hat {\\textbf Y}, \\textbf Y) = - \\textbf 1_{n}^T(\\textbf Y \\odot log(\\hat {\\textbf Y})\\textbf1-{k}\n",
    "$$\n",
    "\n",
    "In our implementation, we will assume that the arguments to the loss function are always matrices of size $n \\times k$. In the case of regression, $k = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "210ba780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares(y, y_hat) :\n",
    "    return 0.5 * np.sum((y_hat - y) * (y_hat - y))\n",
    "\n",
    "def cce(Y, Y_hat) :\n",
    "    return -np.sum(Y * np.log(Y_hat))\n",
    "\n",
    "losses = {\"least_squares\": least_squares, \"cce\": cce}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084868bc",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "Here, we will look at two parts :\n",
    "\n",
    "### Network architecture\n",
    "\n",
    "The following components mainly determine the structure of the network :\n",
    "- Number of layers\n",
    "- Number of neuron per layer\n",
    "We will use $l$ to index the layers. The network has $L$ layers in all.\n",
    "- $l = 0$ : Input layer\n",
    "- $1 \\le l \\le L - 1$ : Hidden layers\n",
    "- $l = L$ : Output layer\n",
    "\n",
    "We shall represent the number of layers and neurons using a list `layers`. The variable $L$ will never make an explicit appearance anywhere, instead will use `range(len(layers))` to iterate through the layers.\n",
    "\n",
    "| Layer           | Number of neurons |\n",
    "| -----------     | -----------       |\n",
    "| Input layer     | `layers[0]`       |\n",
    "| Hidden layer 1  | `layers[1]`       |\n",
    "| Hidden layer 2  | `layers[2]`       |\n",
    "| Hidden layer 3  | `layers[3]`       |\n",
    "| **.......**     | `layers[...]`     |\n",
    "| Output layer    | `layers[-1]`      |\n",
    "\n",
    "One useful task is to compute the total number of parameters in each network. This will come handy later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60cb1a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_params(layers) :\n",
    "    num_params = 0\n",
    "    for l in range(1, len(layers)) :\n",
    "        num_weights = layers[l - 1] * layers[l]\n",
    "        num_biases = layers[l]\n",
    "        num_params += (num_weights + num_biases)\n",
    "    return num_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326183b6",
   "metadata": {},
   "source": [
    "### Parameter initialization\n",
    "\n",
    "- The weight matrix at layer $l$ has a size of `layers[l - 1] x layers[l]`\n",
    "- The bias at layer $l$ is a vector of size `layers[l]`\n",
    "- We will store all these weights in a list `w` of the same size as `layers`. So, `W[l]` will correspond to $\\textbf W_l$. Since there are $L$ weight matrices `W[0]` would be set to `None`. Recall that size of the list if $L + 1$\n",
    "- A similar list would be required for `b`\n",
    "\n",
    "To make the gradient descent update simpler, it will be useful to have a **master vector, $\\boldsymbol \\theta$, that has a refernce to all the parameters in the network**. We will do the same for the gradients $\\boldsymbol \\theta^{(g)}$. So, whenever $\\boldsymbol \\theta$ is updated, the weights $\\textbf W_l$ will also be updated and vice-versa\n",
    "\n",
    "One way to do that is to first start with the master vector and then reshape chunks of it into the dimensions of a weight matrix matrix. Reshaping as arrays usually returns a view of an array and not a copy. Visit [this link](https://numpy.org/doc/stable/user/basics.copies.html) to know more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c75d5f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(layers) :\n",
    "    num_params = count_params(layers)\n",
    "    \n",
    "    W = [None for _ in range(len(layers))]\n",
    "    b = [None for _ in range(len(layers))]\n",
    "    gW = [None for _ in range(len(layers))]\n",
    "    gb = [None for _ in range(len(layers))]\n",
    "    \n",
    "    \n",
    "    # Sample for N(0, 1) to initialize the parameters\n",
    "    \n",
    "    theta = rng.standard_normal(num_params) # Master params\n",
    "    gtheta = np.zeros(num_params) # Master grads\n",
    "    \n",
    "    # (start, end) specify the portion of the theta that \n",
    "    # corresponds to the parameter, W_l ot b_l\n",
    "    start, end = 0, 0\n",
    "    \n",
    "    for l in range(1, len(layers)) :\n",
    "        # Reshaping the section (start, end) and assign it to W[l]\n",
    "        end = start + layers[l - 1] * layers[l]\n",
    "        W[l] = theta[start: end].reshape(layers[l - 1], layers[l])\n",
    "        gW[l] = gtheta[start: end].reshape(layers[l - 1], layers[l])\n",
    "        \n",
    "         # Reshaping the section (start, end) and assign it to b[l]\n",
    "        start, end = end, end + layers[l]\n",
    "        b[l] = theta[start: end].reshape(layers[l])\n",
    "        gb[l] = gtheta[start: end].reshape(layers[l])\n",
    "        \n",
    "        start = end\n",
    "        \n",
    "    return theta, gtheta, W, b, gW, gb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ef4c72",
   "metadata": {},
   "source": [
    "We are now ready to initialize the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c0061dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init(self, layers, activation_choice=\"relu\", output_choice=\"softmax\", loss_choice=\"cce\") :\n",
    "    \n",
    "    self.layers = layers\n",
    "    \n",
    "    # Parameters and gradients\n",
    "    self.theta, self.gtheta, self.W, self.b, self.gW, self.gb = init_params(layers)\n",
    "    \n",
    "    # Activation functions\n",
    "    self.ghid = hidden_act[activation_choice]\n",
    "    self.grad_ghid = grad_hidden_act[activation_choice]\n",
    "    self.gout = output_act[output_choice]\n",
    "    \n",
    "    # Loss\n",
    "    self.loss = losses[loss_choice]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056d139a",
   "metadata": {},
   "source": [
    "## Forward Pass\n",
    "\n",
    "The forward pass algorithm is as follows. First, we initialize $\\textbf A_0 = \\textbf X$. Then, we iteratively compute the pre-activations and the activations for every layer $l$ using the equations given below :\n",
    "\n",
    "$$\n",
    "    \\textbf Z_l = \\textbf A_{l-1}\\textbf W_{l} + \\textbf b_{l}\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\textbf A_l = g(\\textbf Z_l)\n",
    "$$\n",
    "\n",
    "Finally, the network's output is given by : $\\hat {\\textbf y} = \\textbf A_L$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "861862a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, X) :\n",
    "    self.Z = [None for _ in range(len(self.layers))]\n",
    "    self.A = [None for _ in range(len(self.layers))]\n",
    "    self.A[0] = X\n",
    "    self.Z[0] = X\n",
    "    \n",
    "    for l in range(1, len(self.layers)) :\n",
    "        self.Z[l] = self.A[l - 1] @ self.W[l] + self.b[l]\n",
    "        self.A[l] = self.ghid(self.Z[l])\n",
    "            \n",
    "    self.A[-1] = self.gout(self.Z[-1])\n",
    "    return self.A[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3053bfc1",
   "metadata": {},
   "source": [
    "## Backward Pass\n",
    "\n",
    "The backward pass algorithm is as follows. We first initialize the gradients at layer $L$ as $\\textbf Z_L^{(g)} = \\hat {\\textbf Y} - \\textbf Y$. It is fortunate that this is true for both regression and classification. The other gradients can then be iteratively updated using these equations :\n",
    "\n",
    "**NOTATION** : $ \\textbf V_{l}^{(g)}$ denotes the gradient of $\\textbf V$ at layer $l$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "    \\textbf W_l^{(g)} = \\textbf A_{l-1}^{T}\\textbf Z_{l}^{(g)}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "    \\textbf b_l^{(g)} = \\textbf Z_{l}^{(g)^T}\\textbf 1_{n}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "    \\textbf A_{l-1}^{(g)} = \\textbf Z_{l}^{(g)}\\textbf W_{l}^{T}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "    \\textbf Z_{l-1}^{(g)} = \\textbf A_{l-1}^{(g)} \\odot g'(\\textbf Z_{l-1})\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "An important point to note is the use of `self.gw[1][:, :]` while updating the gradient of the weights and not `self.gW[1]`. `self.gw[1][:, :]` does an in-place update, thus maintaining a link with the master params namely `self.theta`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84a70b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(self, Y, Y_hat) :\n",
    "    gZ = [None for _ in range(len(self.layers))]\n",
    "    gA = [None for _ in range(len(self.layers))]\n",
    "    gZ[-1] = Y_hat - Y\n",
    "    \n",
    "    for l in range(len(self.layers) - 1, 0, -1) :\n",
    "        self.gW[l][:, :] = self.A[l - 1].T @ gZ[l]\n",
    "        self.gb[l][:] = np.sum(gZ[l].T, axis=1)\n",
    "        gA[l - 1] = gZ[l] @ self.W[l].T\n",
    "        gZ[l - 1] = gA[l - 1] * self.grad_ghid(self.Z[l - 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63775865",
   "metadata": {},
   "source": [
    "## Fit\n",
    "\n",
    "We now have all the ingredients to fit a model using gradient descent. We will use **mini-batch gradient descent**. The batch-size, learning rate and number of epochs will be hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4e141a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(self, X, Y, lr=0.01, epochs=100, batch_size=100) :\n",
    "    self.losses = []\n",
    "    \n",
    "    for epoch in range(epochs) :\n",
    "        # Compute the loss\n",
    "        Y_hat = self.forward(X)\n",
    "        self.losses.append(self.loss(Y, Y_hat))\n",
    "        \n",
    "        # Shuffle the dataset\n",
    "        indices = np.arange(X.shape[0])\n",
    "        \n",
    "        # Use rng.shuffle to maintain reproducibility\n",
    "        rng.shuffle(indices)\n",
    "        X, Y = X[indices], Y[indices]\n",
    "        \n",
    "        # Number of batched\n",
    "        num_batches = X.shape[0] // batch_size\n",
    "        \n",
    "        # Mini-batch GD\n",
    "        for b in range(num_batches) :\n",
    "            Xb = X[b * batch_size : (b + 1) * batch_size]\n",
    "            Yb = Y[b * batch_size : (b + 1) * batch_size]\n",
    "    \n",
    "            # Compute the predictions for this batch\n",
    "            Y_hatb = self.forward(Xb)\n",
    "            \n",
    "            # Compute the gradients for this batch\n",
    "            self.backward(Yb, Y_hatb)\n",
    "            \n",
    "            # Update the gradients of all parameters. \n",
    "            # -= is used for in-place update\n",
    "            self.theta -= lr * self.gtheta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ec6eaa",
   "metadata": {},
   "source": [
    "## Predict\n",
    "\n",
    "Finally, we can use a trained model to predict the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bf556a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, X) :\n",
    "    Y_hat = self.forward(X)\n",
    "    \n",
    "    if(X.shape[-1] == -1) :\n",
    "        # Regression\n",
    "        return Y_hat\n",
    "    else :\n",
    "        # Classification\n",
    "        return np.argmax(Y_hat, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cc4b9e",
   "metadata": {},
   "source": [
    "## Pluggin in\n",
    "\n",
    "We can now plug all of this into our `Network` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16ac8dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Network.__init__ = init\n",
    "Network.forward = forward\n",
    "Network.backward = backward\n",
    "Network.fit = fit\n",
    "Network.predict = predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eb02c0",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "### Data\n",
    "\n",
    "We will import the digits dataset from `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f39836a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample image with label :  0\n",
      "(1797, 8, 8)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "X = digits.images\n",
    "y = digits.target\n",
    "\n",
    "# Normalize the data so that all the features lie in (0, 1)\n",
    "X /= np.max(X)\n",
    "\n",
    "plt.imshow(X[0])\n",
    "print(\"Sample image with label : \", y[0])\n",
    "print(X.shape)\n",
    "\n",
    "# Reshape input\n",
    "X = X.reshape(-1, 64)\n",
    "\n",
    "# Input size\n",
    "isize = X.shape[-1]\n",
    "\n",
    "# Output size\n",
    "osize = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8dde4ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_encoder(y) :\n",
    "    k = len(np.unique(y))\n",
    "    return np.eye(k)[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc9b6e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (1078, 64) (1078, 10)\n",
      "Test data shape :  (719, 64) (719, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ranfom_state has the same seed value as rng\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=seed)\n",
    "\n",
    "Y_train = onehot_encoder(y_train)\n",
    "Y_test = onehot_encoder(y_test)\n",
    "\n",
    "print(\"Training data shape : \", X_train.shape, Y_train.shape)\n",
    "print(\"Test data shape : \", X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5162c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data size :  719\n",
      "Accuracy :  96.3839\n",
      "Number of parameters :  2410\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the network\n",
    "layers = [isize, 32, osize]\n",
    "network = Network(layers, activation_choice=\"sigmoid\", output_choice=\"softmax\", loss_choice=\"cce\")\n",
    "\n",
    "# Fit the network on data\n",
    "epochs = 50\n",
    "network.fit(X_train, Y_train, lr=0.01, epochs=epochs, batch_size=10)\n",
    "\n",
    "# Plot the losses\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(range(epochs), network.losses)\n",
    "plt.title(\"Loss vs Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"CCE Loss\")\n",
    "\n",
    "\n",
    "# Compute the accuracy\n",
    "y_hat = network.predict(X_test)\n",
    "accuracy = (np.sum(y_hat == y_test) / X_test.shape[0]) * 100\n",
    "\n",
    "print(\"Test data size : \", X_test.shape[0])\n",
    "print(\"Accuracy : \", round(accuracy, 4))\n",
    "print(\"Number of parameters : \", count_params(layers))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
