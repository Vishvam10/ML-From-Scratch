{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccac8f81",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "\n",
    "- Is a popular **non-parametric supervised ML algorithm that can be used for both classification and regression tasks**\n",
    "- The tree itself is a model in decision trees and we would like to estimate an optimal tree structure from the given training data.\n",
    "    - **The internal node contains conditions on features. Depending on the outcome of the comparision, we take an appropriate path in the tree. This process is continued till we reach a leaf node**\n",
    "    - In case of classification, leaf nodes containing label and in case of regression, the prediction is obtained by taking sample mean of labels of the subset of training examples present in that leaf node.\n",
    "    \n",
    "We will implement decision tree for classification with **ID3 algorithm**\n",
    "\n",
    "\n",
    "## Relevant Formulae \n",
    "\n",
    "### Impurity Measure\n",
    "\n",
    "\n",
    "If we define $p_i,k$ to be the proportion of data points in node $i$ ($\\mathcal{R}(i)$) assigned to class $k$, where $k = 1,...,K$, then :\n",
    "\n",
    "$$\n",
    "    p_{i,k} = \\frac {1}{N_i} \\sum \\limits_{x^{(i)} \\in \\mathcal{R}_i} \\mathcal {1}(y^{(i)} = k)\n",
    "$$\n",
    "\n",
    "where $N_i$ is the number of samples in region $\\mathcal {R}_i$\n",
    "\n",
    "\n",
    "### Misclassification Error\n",
    "\n",
    "It is the proportion of misclassified examples in node $i$ :\n",
    "\n",
    "$$\n",
    "    Q_i(T) = 1 - p_{i,k(i)} = \\frac {1}{N_i} \\sum \\limits_{x^{(i)} \\in \\mathcal{R}_i} \\mathcal {1}(y^{(i)} \\ne k)\n",
    "$$\n",
    "\n",
    "where $k(i) = arg_k max p_{i,k}$ = **prediction of class in node $i$**\n",
    "\n",
    "\n",
    "### Gini Index\n",
    "\n",
    "$$\n",
    "    G_i = \\sum \\limits_{k=1}^{K} p_{i,k}(1 - p_{i,k})\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "### Entropy\n",
    "\n",
    "Entropy of node $i$ is given by :\n",
    "\n",
    "$$\n",
    "    H_i = - \\sum \\limits_{k=1}^{n} p_{i,k} (log_2 p_{i,k})\n",
    "$$\n",
    "\n",
    "**In ID3**, entropy is calculated for each remaining attribute. **The attribute with the smallest entropy is used to split the dataset on a given iteration.**\n",
    "\n",
    "\n",
    "### Information Gain\n",
    "\n",
    "- Information Gain (IG) is a **measure of the effectiveness** of an attribute in classifying the training data\n",
    "- It is simply the **expected reduction in entropy** casusd by partitioning the examples according to the chosen attribute\n",
    "\n",
    "Intuitively,\n",
    "\n",
    "**IG(attribute) = Entropy of dataset - Entropy of attribute**\n",
    "\n",
    "Formally, the information gain IG(S,A) of an attribute A, relative to collection of examples S, is defined as :\n",
    "\n",
    "$$\n",
    "    IG(S,A) = Entropy(S) - \\sum \\limits_{v \\in Values(A)} \\frac {|S_v|} {|S|} Entropy(S_v)\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "where $Entropy(S)$ is the entropy of dataset, $\\sum \\limits_{v \\in Values(A)} \\frac {|S_v|} {|S|} Entropy(S_v)$ is the entropy of the attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71f27031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.220446049250313e-16"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "eps = np.finfo(float).eps\n",
    "eps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26193f8a",
   "metadata": {},
   "source": [
    "Here, `eps` is the smallest representable number. At times we get $log(0)$ or $0$ in the denominator. **To avoid that, we are going to use this.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b006cc",
   "metadata": {},
   "source": [
    "We will be using a synthetic dataset to demonstrate decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff87e26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    ['overcast', 'hot', 'high', 'FALSE', 'yes'],\n",
    "    ['overcast', 'cool', 'normal', 'TRUE', 'yes'],\n",
    "    ['overcast', 'mild', 'high', 'TRUE', 'yes'],\n",
    "    ['overcast', 'hot', 'normal', 'FALSE', 'yes'],\n",
    "    ['rainy', 'mild', 'high', 'FALSE', 'yes'],\n",
    "    ['rainy', 'cool', 'normal', 'FALSE', 'yes'],\n",
    "    ['rainy', 'cool', 'normal', 'TRUE', 'no'],\n",
    "    ['rainy', 'mild', 'normal', 'FALSE', 'yes'],\n",
    "    ['rainy', 'mild', 'high', 'TRUE', 'no'],\n",
    "    ['sunny', 'hot', 'high', 'FALSE', 'no'],\n",
    "    ['sunny', 'hot', 'high', 'TRUE', 'no'],\n",
    "    ['sunny', 'mild', 'high', 'FALSE', 'no'],\n",
    "    ['sunny', 'cool', 'normal', 'FALSE', 'yes'],\n",
    "    ['sunny', 'mild', 'normal', 'TRUE', 'yes']\n",
    "]\n",
    "\n",
    "cols = ['outlook','temp','humidity','windy','play']\n",
    "\n",
    "df = pd.DataFrame(data, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab5559fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 5)\n",
      "play\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.keys()[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f81707dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['overcast', 'hot', 'high', 'FALSE', 'yes'],\n",
       "       ['overcast', 'cool', 'normal', 'TRUE', 'yes'],\n",
       "       ['overcast', 'mild', 'high', 'TRUE', 'yes'],\n",
       "       ['overcast', 'hot', 'normal', 'FALSE', 'yes'],\n",
       "       ['rainy', 'mild', 'high', 'FALSE', 'yes'],\n",
       "       ['rainy', 'cool', 'normal', 'FALSE', 'yes'],\n",
       "       ['rainy', 'cool', 'normal', 'TRUE', 'no'],\n",
       "       ['rainy', 'mild', 'normal', 'FALSE', 'yes'],\n",
       "       ['rainy', 'mild', 'high', 'TRUE', 'no'],\n",
       "       ['sunny', 'hot', 'high', 'FALSE', 'no'],\n",
       "       ['sunny', 'hot', 'high', 'TRUE', 'no'],\n",
       "       ['sunny', 'mild', 'high', 'FALSE', 'no'],\n",
       "       ['sunny', 'cool', 'normal', 'FALSE', 'yes'],\n",
       "       ['sunny', 'mild', 'normal', 'TRUE', 'yes']], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "664c32a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     yes\n",
      "1     yes\n",
      "2     yes\n",
      "3     yes\n",
      "4     yes\n",
      "5     yes\n",
      "6      no\n",
      "7     yes\n",
      "8      no\n",
      "9      no\n",
      "10     no\n",
      "11     no\n",
      "12    yes\n",
      "13    yes\n",
      "Name: play, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df[df.keys()[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "577a33e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_entropy_whole(df) :\n",
    "    \n",
    "    # Last column is the target variable\n",
    "    target = df.keys()[-1]\n",
    "    \n",
    "    # Initialization\n",
    "    overall_entropy = 0\n",
    "    \n",
    "    # Possible values of target\n",
    "    values_in_target = df[target].unique()\n",
    "    \n",
    "    for val in values_in_target :\n",
    "        print(val)\n",
    "        p = df[target].value_counts()[val] / len(df[target])\n",
    "        print(p)\n",
    "        overall_entropy += (-p * np.log2(p))\n",
    "    \n",
    "    return overall_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e4864b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "0.6428571428571429\n",
      "no\n",
      "0.35714285714285715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9402859586706311"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_entropy_whole(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06e568f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_entropy_whole(df) :\n",
    "    \n",
    "    # Last column is the target variable\n",
    "    target = df.keys()[-1]\n",
    "    \n",
    "    # Initialization\n",
    "    overall_entropy = 0\n",
    "    \n",
    "    # Possible values of target\n",
    "    values_in_target = df[target].unique()\n",
    "    \n",
    "    for val in values_in_target :\n",
    "        p = df[target].value_counts()[val] / len(df[target])\n",
    "        overall_entropy += (-p * np.log2(p))\n",
    "    \n",
    "    return overall_entropy\n",
    "\n",
    "\n",
    "\n",
    "def find_entropy_of_attribute(df, attribute) :\n",
    "    # Last column is the target variable\n",
    "    target = df.keys()[-1]\n",
    "    \n",
    "    # Initialization\n",
    "    entropy_attribute = 0\n",
    "\n",
    "    \n",
    "    # Possible values of target\n",
    "    values_in_target = df[target].unique()\n",
    "    \n",
    "    # Gives different features in the passed in attribute. For eg. 'hot', 'cold', in temperature, etc.\n",
    "    values_in_attr = df[attribute].unique()\n",
    "    \n",
    "        \n",
    "    for val_attr in values_in_attr :\n",
    "        overall_entropy = 0\n",
    "\n",
    "        for val_target in values_in_target :\n",
    "            num = len(df[attribute][df[attribute] == val_attr][df[target] == val_target])\n",
    "            den = len(df[attribute][df[attribute] == val_attr])\n",
    "            p = num / (den + eps)\n",
    "            overall_entropy += -p * np.log2(p + eps)\n",
    "        p2 = den / len(df)\n",
    "        entropy_attribute += -p2 * overall_entropy\n",
    "    return abs(entropy_attribute)\n",
    "\n",
    "def find_best_attribute_to_divide(df):\n",
    "    IG = []\n",
    "\n",
    "    all_attributes = df.keys()[:-1]\n",
    "    \n",
    "    for attribute in all_attributes:\n",
    "        IG.append(find_entropy_whole(df) - find_entropy_of_attribute(df, attribute))\n",
    "    index_of_attribute_with_max_IG = np.argmax(IG)\n",
    "    best_attribute = all_attributes[index_of_attribute_with_max_IG]\n",
    "    \n",
    "    return best_attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28d9f8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of the attribute \"outlook\" is : 0.6935361388961914\n",
      "Entropy of the attribute \"temp\" is : 0.9110633930116756\n",
      "Entropy of the attribute \"humidity\" is : 0.7884504573082889\n",
      "Entropy of the attribute \"windy\" is : 0.892158928262361\n"
     ]
    }
   ],
   "source": [
    "for attribute in df.keys()[:-1]:\n",
    "    print(f'Entropy of the attribute \"{attribute}\" is :', find_entropy_of_attribute(df, attribute))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1de91661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'outlook'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_best_attribute_to_divide(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e48dd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildTree(df, tree=None) :\n",
    "    target = df.keys()[-1]\n",
    "    node = find_best_attribute_to_divide(df)\n",
    "    attValue = np.unique(df[node])\n",
    "    print(node)\n",
    "    if tree is None :\n",
    "        tree = {}\n",
    "        tree[node] = {}\n",
    "\n",
    "    for value in attValue :\n",
    "        subtree = df[df[node] == value].reset_index(drop=True)\n",
    "        clValue, counts = np.unique(subtree['play'], return_counts=True)\n",
    "\n",
    "        # Checking purity of subset\n",
    "        if len(counts) == 1: \n",
    "            # Leaf Node\n",
    "            tree[node][value] = clValue[0]\n",
    "        else:\n",
    "            # If not a leaf node, call the function recursively\n",
    "            tree[node][value] = buildTree(subtree) \n",
    "    \n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ed8cd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outlook\n",
      "windy\n",
      "humidity\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'outlook': {'overcast': 'yes',\n",
       "  'rainy': {'windy': {'FALSE': 'yes', 'TRUE': 'no'}},\n",
       "  'sunny': {'humidity': {'high': 'no', 'normal': 'yes'}}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buildTree(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
